{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1d4b2c-03b7-4740-a7f1-fd158fde7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/spam_utf8.csv\", encoding=\"ISO-8859-1\")\n",
    "df.to_csv(\"data/spam_utf8.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1401ce-3018-4a76-8424-f38132a66138",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9b6dc8-6491-4527-9232-d611ded510dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1) #dropping as most of the last 3 have nulls only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d0ed3d-a8f0-4a02-b8ad-93b51c0b820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'v1':'target','v2':'text'},inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdcda33-322e-4887-9605-af72211bf5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label-encoding to transform target ham and spam into 0 and 1\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "df['target']=encoder.fit_transform(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ffb36d-cba6-4f15-a154-12fa4deb9fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates(keep='first')\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720035fa-d2a5-41de-9ede-3c3b508030aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting for better understanding and visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "plt.pie(df['target'].value_counts(),labels=['ham','spam'],autopct=\"%0.2f\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871b1858-98c3-434e-a9d7-ee0f2c8840fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measuring number of characters\n",
    "def len_measurement(list_n):\n",
    "    return len(list_n)\n",
    "df['size_char']=df['text'].apply(len_measurement)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e36ec0-43e5-4f78-9280-6fbb907f1933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measuring number of words\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "def word_count(list_m):\n",
    "    tokens= word_tokenize(list_m)\n",
    "    return len(tokens)\n",
    "df['words']=df['text'].apply(word_count)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3777d12b-d073-47da-8126-c0633b6d38aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measuring number of sentences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "def sentence_count(list_m):\n",
    "    tokens_sent=sent_tokenize(list_m)\n",
    "    return len(tokens_sent)\n",
    "df['sentences']=df['text'].apply(sentence_count)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b59b360-5ba3-48a5-9cb5-e38c9ab98ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ham\n",
    "df[df['target']==0][['size_char','words','sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f7ecd-c097-4e0a-8bc8-a9b2899d9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ham\n",
    "df[df['target']==1][['size_char','words','sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc426020-c384-481c-81b2-e0cfe6494dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so spam messages in general contain more characters,words and sentences.\n",
    "#seaborn because it makes visualisation better.\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.histplot(df[df['target']==0]['size_char'],color='blue')\n",
    "sns.histplot(df[df['target']==1]['size_char'],color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e96228-d67c-4026-b1f4-538c2cdd5cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[df['target']==0]['words'],color='blue')\n",
    "sns.histplot(df[df['target']==1]['words'],color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c74784-f00b-4367-b59d-c904664b3fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,hue='target') #blue=ham,rest spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037e2770-2ff4-437f-a4b1-f9cfd05c87e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only numeric datas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numeric_df = df.select_dtypes(include='number')\n",
    "sns.heatmap(numeric_df.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258f16a6-ffae-4772-bd2f-8b44069f37fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing(text hole evabe korbo):\n",
    "#1)lower case\n",
    "#2)tokenization\n",
    "#3)removing special characters\n",
    "#4)removing punctuations and stop words\n",
    "#5)stemming\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c131fb59-1b06-413c-bfb0-86b170a1d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "\n",
    "ps = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punct = set(string.punctuation)\n",
    "\n",
    "def transform_text(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    # filter alphanumeric, remove stopwords/punctuation, then stem\n",
    "    return \" \".join(\n",
    "        ps.stem(tok)\n",
    "        for tok in tokens\n",
    "        if tok.isalnum() \n",
    "        and tok not in stop_words \n",
    "        and tok not in punct\n",
    "    )\n",
    "\n",
    "df['text'] = df['text'].apply(transform_text)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec4123b-01d0-4507-976f-74a9d1dd508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=df[df['target']==1]['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35787de1-1d81-4774-8edb-7ef9f13af212",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_corpus=[]\n",
    "for msg in df_list:\n",
    "    for word in msg.split():\n",
    "        spam_corpus.append(word)\n",
    "len(spam_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb617033-547b-40d6-aab0-385df953c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "data_spam=pd.DataFrame(Counter(spam_corpus).most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d71b038-9200-4b44-a291-4e0af7eea8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249ad9ef-7a5e-4057-a549-4388fceb6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list2=df[df['target']==0]['text'].tolist()\n",
    "ham_corpus=[]\n",
    "for msg in df_list2:\n",
    "    for word in msg.split():\n",
    "        ham_corpus.append(word)\n",
    "len(ham_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98279ad-8875-450f-8d51-5d291e27cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ham=pd.DataFrame(Counter(ham_corpus).most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead3d87-9b0e-4c8c-bca3-fcd71e11a81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Building\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "vectorizer= CountVectorizer()\n",
    "tfidfvec=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e4f537-3d55-49fb-a476-a9a1f59aa1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tfidfvec.fit_transform(df['text']).toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee759e7-e497-4840-94b4-fd06534f1799",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36378b0d-7140-4b01-955b-2a84a32e20f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4f267c-2c28-4d35-9df0-8dca52279682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab2b65-d342-4d58-b4c8-7d547f72ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb=GaussianNB()\n",
    "mnb=MultinomialNB()\n",
    "bnb=BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5990e1f3-3d76-4902-bc63-01069ad3e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using gnb\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred=gnb.predict(X_test)\n",
    "print(f\"The accuracy of your model is={accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"The accuracy of your model is={confusion_matrix(y_test,y_pred)}\")\n",
    "print(f\"The accuracy of your model is={precision_score(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e10d1f-f561-4485-88b2-856e2650e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using bnb\n",
    "bnb.fit(X_train,y_train)\n",
    "y_pred2=bnb.predict(X_test)\n",
    "print(f\"The accuracy of your model is={accuracy_score(y_test,y_pred2)}\")\n",
    "print(f\"The accuracy of your model is={confusion_matrix(y_test,y_pred2)}\")\n",
    "print(f\"The accuracy of your model is={precision_score(y_test,y_pred2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e124b159-0df4-4047-8c0a-edb7b1476512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf\n",
    "\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred=gnb.predict(X_test)\n",
    "print(f\"The accuracy of your model is={accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"The accuracy matrix is={confusion_matrix(y_test,y_pred)}\")\n",
    "print(f\"The accuracy of the model is={precision_score(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8f4f7a-04b8-4f1b-9848-353178a79cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnb after tfidf\n",
    "bnb.fit(X_train,y_train)\n",
    "y_pred2=bnb.predict(X_test)\n",
    "print(f\"The accuracy of your model is={accuracy_score(y_test,y_pred2)}\")\n",
    "print(f\"The matrix model is={confusion_matrix(y_test,y_pred2)}\")\n",
    "print(f\"The accuracy of your model is={precision_score(y_test,y_pred2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2091a66-d33e-47d9-903a-e7542f15a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnb\n",
    "mnb.fit(X_train,y_train)\n",
    "y_pred3=mnb.predict(X_test)\n",
    "print(f\"The accuracy of model is={accuracy_score(y_test,y_pred3)}\")\n",
    "print(f\"The accuracy matrix is={confusion_matrix(y_test,y_pred3)}\")\n",
    "print(f\"The accuracy of model is={precision_score(y_test,y_pred3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c803c222-ea62-4faa-be5f-044ca176710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from every experiment,it's best\n",
    "tfidfvec=TfidfVectorizer(max_features=3000)\n",
    "X=tfidfvec.fit_transform(df['text']).toarray()\n",
    "y=df['target'].values\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=2)\n",
    "\n",
    "mnb.fit(X_train,y_train)\n",
    "y_pred3=mnb.predict(X_test)\n",
    "print(f\"The accuracy of model is={accuracy_score(y_test,y_pred3)}\")\n",
    "print(f\"The accuracy matrix of model is={confusion_matrix(y_test,y_pred3)}\")\n",
    "print(f\"The accuracy of my model is={precision_score(y_test,y_pred3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e102ecf-243d-406b-a5d8-80df9e0bf7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(mnb, \"models/mnb.pkl\")\n",
    "joblib.dump(vectorizer, \"models/vectorizer.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f61e8-ca0d-44de-a6fc-d632586a2247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
